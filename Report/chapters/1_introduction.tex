\chapter{Introduction}\label{sec:introduction}

A crucial property of micro aerial vehicle (MAV) navigation and control is the estimation of their position towards the environment. There exist several methods to achieve this, a popular one being the use of cameras. The cameras can be either placed on the MAV itself or statically in the environment for external tracking. In order to estimate the pose specific cues in the camera image must be located. This works well as long as there are significant features available. Since conventional camera sensors generally provide not more than 30 frames per second, fast motion blurs the camera image and thus hinders feature detection.  Therefore, during an aggressive maneuver, tracking is usually lost and needs to be reacquired after the camera data are clear again. To re-establish a lost track already know cues need to be found, inducing a latency for tracking. A possible solution to this drawback is the use of cameras with higher frame rates. This comes at an expense though, not only in terms of data processing but also in price. Therefore we wanted to find a solution which is not only computationally cheaper, while still providing high speed, but also comes at a reasonable price.
The Institute of Neuroinformatics at the University of Zurich and ETH has developed a dynamic vision sensor(DVS) which should provide the solution. Inspired by the human retina, each pixel fires asynchronously and only if there is change in illumination on a specific pixel. Thus, the data from the DVS are events, where an event stores the following values:

\begin{itemize}
	\item Position \{x, y\}
	\item Polarity \{on \textbar\ off\}
	\item Time stamp \{t\}
\end{itemize}

Therefore events depict the time and place of a single impulse rather than pixels in a frame. The change of illumination is thereby binary, i.e. only the direction of change is advertised. The time stamp is generated by DVS internals and has microsecond resolution. This provides high sampling rates, while maintaining a relatively low data output. As the processing is done asynchronously the sampling rate is not fixed but rather dependent on the amount of overall activity on the pixels. There are several reasons for that, for example the limit set by the serial time-stamping mechanism, as well as the data output via USB 2.0. Nevertheless, the camera provides up to 1 million events per second. Employing special circuitry comes at an expense though as the camera has a comparably low resolution of 128x128 pixels. For a deeper insight into the camera technology please refer to \cite{DVS}.
In order to facilitate tracking, given the high temporal resolution of the DVS, we decided to use active markers in the form of differently pulsed LEDs with the DVS. The feasibility and high robustness of this approach had already been demonstrated by \cite{Matthias}. The LEDs were attached to a quadrotor helicopter, which would then be tracked by the DVS.  For the marker tracking we developed an algorithm able to track several LEDs pulsed with different frequencies. For estimating the pose we used an already existing library. In the following part the challenges an preparations are discussed. After that a detailed description of the algorithm will be given followed by the experiments and evaluation. Finally a conclusion summarizes our findings as well as discusses possible future improvements and projects.
