\chapter{Approach}\label{sec:approach}

\section{Considerations and Challenges}\label{sec:considerations}

First of all, working with special hardware like the DVS, which functions differently than conventional cameras, requires a different approach to handling and processing the data from ground up. Using normal cameras, naturally conventional vision algorithms are based on the analysis of frames. In order to make use of the asynchronous behavior an image-based approach thus is not feasible, i.e. the algorithm had to make use of the event-based behavior of the DVS.
Another property to keep in mind with the DVS is the fact that data is only provided if there is a change in illumination, e.g. motion. This means that a static input will not generate any significant output apart from noise.
Another limitation is the low spatial resolution. This makes it unfeasible to detect small features in the field of view. Furthermore, the low resolution will have a higher uncertainty of the position of a feature or marker respectively in image space compared to conventional cameras.
As previously mentioned, the sampling frequency, i.e. also the accuracy will vary. Therefore it was not clear beforehand what frequencies could be handled by the DVS under our conditions with the quadrotor.

\section{Preparation}\label{sec:preparation}

In this paragraph the preparations necessary before starting to implement the tracking algorithm are discussed. These comprise of writing a driver interface in C++ to the DVS as well as building a set of blinking LEDs.

\subsection{C++ interface to the DVS}\label{sec:interface}

The framework provided with the DVS (jAER) is completely written in Java as well as the tracking algorithm develop by [Mathias]. Since we wanted to implement the algorithm in C++ due to performance and portability (e.g. to embedded systems) considerations it was necessary to write a driver interface for the DVS in C++ first. Thesycon [footnote], the provider of the USB device driver, already provides basic frameworks for different programming languages to interface with their driver.  A basic interface was written to pull the event data from the DVS. Similar to jAER, the events were wrapped up in packets of several events. The packet size depends on the junk of data which arrives at once from the USB . This not only makes sense as the data arrive in chunks of up to several hundred events from the USB buffer; packet-based processing is also advantageous for certain operations, e.g. if they are computationally costly and furthermore if single events don’t provide enough relevant information to be processed individually. 

\subsection{LED markers}\label{sec:leds}

In order to build a set of blinking LEDs with different frequencies we used the bronze board from INI which is based on an AVR32. A USB interface provides the means for simple programming and communication with the microcontroller. Although a less powerful microprocessor would have been sufficient, a number of independent Pulse-Width-Modulation (PWM) drivers was an important property in order to pulse several LEDs with different frequencies. The AVR has 7 PWM drivers, from which 5 are free to use.  An already existing example C code [link] was taken and adapted to our needs. A python script was also written to remotely adjust the PWMs via USB from a PC. 
The choice of LEDs was also important, since they should be well visible. The ideal LED for our project would be high power and with a wide emission angle. Since the DVS is very sensitive to the infrared spectrum, we decided to go for infrared LEDs[type hint]. Finally the accuracy of the induced frequencies was verified with an oscilloscope. In order to find a position and orientation of an object in space at least four reference points are necessary [ref]. Therefore we decided to attach four LEDs to our quadcopter.


\section{The tracking algorithm}\label{sec:tracking}

The following paragraphs describe the separate steps of the tracking algorithm we developed. The approach previously designed by [Mathias] is on a more general level assuming the blinking pattern to be previously unknown. 
As we wanted to design our algorithm for a specific task, namely tracking a helicopter, these constraints gave us the opportunity to simplify our approach. In our setup would be tracking specific LEDs attached to a helicopter, of which we already knew the blinking pattern, as well as the position towards each other. While the approach by [Mathias] starts by finding high-activity clusters, denoting the position of a blinking LED, we decided to take a different approach. Fixing different frequencies to our LEDs allowed us to first filter frequency space to get rid of background noise and extract the relevant information. The resulting signal resembles a square wave with 50\% duty rate. The following section describes the filtering process, as well as the choice of frequencies.


\subsection{Frequency filter}\label{sec:frequencyfilter}

There are two main challenges to consider in frequency analysis:
\begin{itemize}
\item The stable measurement of frequencies
\item The influence of background noise in frequency measurement
\end{itemize}

Having static LEDs in the camera’s “image” the straight-forward approach of measuring the inter-spike-intervals  (ISI) [ A neuroscientific terms for the time interval between two firings of the same neuron, here a pixel] would be evident as changes of LED state(from on to off or vice versa) should generate consecutive events of different polarity  and thus yield to the signal period. This approach should also work for moving LEDs as long as the frequencies are high and the LED velocity is low enough, so that consecutive state changes overlap to generate events on the same pixels. Since this has shown to be true for the maximum possible velocity of the quadrotor towards the camera, we went for this approach.
In order to address the influence of background noise we needed to find out what ISIs were usually generated by it. Therefore, we recorded DVS data over several scenarios by moving the DVS camera over our set of pulsed LEDs fixed to the ground. This included different distances and speeds, as well as varying backgrounds. Thereby, background containing many edges will generate a considerably higher amount of events than uniform backgrounds (e.g. white walls). Evaluating the different data on a frequency histogram we found that most of the movement induced background noise generates frequencies up to around 500Hz [plot]. Thus, to make our LEDs well distinguishable they needed to be pulsed with frequencies above this limit. Additionally to the lower boundary, an upper limit also needed to be considered, as the sampling accuracy of the DVS drops with higher frequencies (Mathias Master thesis). Furthermore, the spacing between the frequencies was also important in order to prevent inaccurate measurement to deliver false detections and thus keep our markers well distinguishable. Last but not least, the frequencies should not be multiples of each other to ensure robustness towards occasional data loss (i.e. if a state change of the LED is missed the period will not be confused the one of another LED). Experiments showed frequencies of 740, 1030, 1320 and 1610 Hz to work well.


\subsection{Frequency period estimation}\label{sec:periodestimation}

Following the assumption of using the ISIs on single pixels for period estimation, where an event denotes a rising or falling edge of the signal, these needed (i.e. the change of polarity of consecutive events) to be taken into account for each pixel first. As we found, two consecutive events on a pixel excited by a blinking LED did not always have different polarity. Instead, several successive events of the same polarity are generated. This can be related to the high sensitivity of the DVS as well as the non-uniform illumination coming from an LED over time. Therefore, it was necessary to observe consecutive events and note a state transition, whenever they were of different polarity. This provides us with two kinds of transitions, namely from positive to negative polarity or vice versa. Two consecutive transitions of the same type would then yield the signal period. 
In order to keep track of the latest events on a per pixel level, we use a 2D array resembling the pixel space of the DVS, where only the latest event for each pixel is stored.  Before inserting a new event into the array, its type is compared to the preceding event.  If their polarities differ a transition is generated including the current timestamp. Similar to an event, pixel location, the transition polarity and timestamp of the transition are stored.
Similar to the previous step each transition is again mapped onto a 2D array with pixel space resolution. To keep track of each transition type two 2D-arrays are used to store the latest transition for each pixel. Following our previous assumption, before insertion of a new transition the time interval to its predecessor is now measured. This provides a period estimate and thus a certain frequency.


\subsection{Frequency accumulation}\label{sec:frequencyaccumulation}

In order to find the relevant frequencies each measurement is weighted with a Gaussian according to its distance to each of the frequencies we want to find. 
This provides us with different likelihoods (according to the magnitude of weight) of having found a relevant frequency. The weights are stored in a weight map, i.e. a 2D-array of pixel-space resolution as before. In order to increase the robustness and to avoid noise induced weights to influence our frequency filter, it was important to gather several weights per pixel to support the hypothesis of having found a pulsed signal. Since we are interested in finding four distinct signals a weight map for each needs to be maintained. Each pixel in the map gathers the sum of weights measured during a certain time. As an interval during which to gather weights 10ms showed to provide robust results. The most likely position of a certain LED was then estimated by taking the pixels with the most support into account, i.e. the ones with the highest weight.  Therefore a set of local maxima of the weight map needs to be maintained. Such a local maximum should denote the position of an LED. Therefore we introduced a minimum distance between maxima. A distance of 15 pixels was chosen, as this is larger than the usual area covered by a single LED. The number of local maxima to maintain was set to three, as experiments showed additional maxima to have a comparably much lower significance.

\section{LED position estimation}\label{sec:positionestimation}

So far the local maxima provide us different hypothesis of the location of each LED. This gives us only a snapshot in time of the current most likely locations though. In order to increase robustness by observing the positions over time as well as taking motion of the quadcopter into account we applied a particle filter. This technique is widely used in robotics for state estimation. For more insight, please refer to [particle filter paper]. The following paragraph describes our application of such a filter.


\subsection{Particle filter}\label{sec:particlefilter}

So far each evaluation of local maxima provides us with three hypotheses denoting the possible marker positions. Each hypothesis is now used to update a particle filter. For each signal we want to find, there is a particle filter with a fixed set of particles. Such a particle stores the following values: the position in pixel-space with sub-pixel resolution, an uncertainty value, the weight of the particle and a time stamp of its creation. The uncertainty of the particle denotes the possible radius in pixels in which the LED could have moved since the last update of the particle representing our motion model. Thus the uncertainty of a particle grows in time, according to the maximum possible speed an LED can move in image space. If the uncertainty reaches a certain threshold, i.e. the uncertainty is too high, the particle expires and is deleted. In the following the process of maintaining the particles is explained:
Initially, the particle filter is empty. For every new hypothesis a candidate particle is created. Thereby, the position and weight are inherited from the hypothesis while the uncertainty is set to a default value of 2 pixels. The latest incoming event marks the time of particle creation.  Each candidate can now become a new particle in the filter or can be merged with an existing one.  Therefore candidates are compared to the existing particles to see if their position falls into the uncertainty radius of an existing particle. In this case, and under the assumption of our motion model, this would mean that the candidate indicates a valid consecutive position in time of an LED. If no existing particle can be updated, the candidate is inserted into the filter, replacing the oldest particle if the filter is full.
During merging two particles, their uncertainties decide upon their contribution for the new particle created. The new position is thus linearly interpolated according to their uncertainty. Similarly, the new weight is a summation of particle values weighted by their uncertainty. The new uncertainty is calculated by a multiplication of Gaussians.


\subsection{Extracting LED positions}\label{sec:ledpositions}

In this final step we need to decide on the definitive positions of the four LEDs. So far we have a particle filter for each LED with a number of particles denoting the most likely positions for the LEDs. The simplest approach would choose from each filter the particle with the highest weight, i.e. the particle with the highest support. Unfortunately though, we found that the frequencies we used were close enough to be ambiguous for frequency estimation. Thus, apart from random noise, close-by frequencies tended have particles of different signal in similar locations. This required then, to find the best valid combination of particles. This means, that each possible combination needs to be checked for a minimum distance between the particles to each other. The significance of a valid combination was found by multiplying the particle weights.
In order to solve this combinational problem a recursive function was used to traverse all the different combinations. Since such combinatorial problem implies many recursions and thus becomes computationally costly we introduced some heuristics to reduce the number of recursions. First, each particle filter was sorted in descending order according to particle weights. This should favor finding the most significant combinations early. In addition, since we were only interested in a limited number of most likely combinations, after finding enough hypotheses a branch would only be expanded if its score was bigger than the least significant score of the hypotheses found so far. For choosing the right combination, we took the straight forward approach of selecting the one with the highest score. 

\subsection{Pose estimation}\label{sec:poseestimation}

Given the LED position, we were now able to estimate the relative pose of the helicopter to the camera. We used an existing algorithm from the openCV [link] library for that purpose. Given the feature points in the objects reference frame, the correspond points in image space, as well as the intrinsic camera parameters and its distortion values the algorithm computes a rotation and translation of the object towards the camera reference frame.

\subsection{Discussion}

It could happen, that position would shortly jump, when the weights of a wrong placement were winning. Another problem in the particle filter approach is the fact that the local maxima, i.e. the position of a single pixel, is taken to update a particle. Since an LED usually produces a blob comprising several pixels on the camera, maxima tend to change position, which gives the particles an oscillating behavior.