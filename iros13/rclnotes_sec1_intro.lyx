#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass IEEEtran
\begin_preamble
\input{tex/preamble.tex}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman palatino
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks true
\pdf_pdfborder true
\pdf_colorlinks true
\pdf_backref page
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date true
\use_refstyle 0
\branch report
\selected 0
\filename_suffix 0
\color #000000
\end_branch
\branch conf
\selected 0
\filename_suffix 0
\color #000000
\end_branch
\branch AC
\selected 1
\filename_suffix 0
\color #682743
\end_branch
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Low-latency localization by Active LEDs Markers tracking
\end_layout

\begin_layout Author
Andrea Censi, Jonas Strubel, Christian Braend, Tobi Delbruck, Davide Scaramuzza
\end_layout

\begin_layout Abstract
TODO
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Itemize

\emph on
Current agile robots use alternative tracking systems.
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
DS: one-two paragraphs dissing Raff D'Andrea
\series default
 
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rule{8.6cm}{3cm}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Discretization-and-latency"

\end_inset

Discretization and latency
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Currently, the agility of a mobile robot is limited by the speed of the
 sensing pipeline.
 More precisely, 
\begin_inset Quotes eld
\end_inset

speed
\begin_inset Quotes erd
\end_inset

 can be quantified in 
\emph on
observations frequency
\emph default
 and 
\emph on
latency
\emph default
 (
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:Discretization-and-latency"

\end_inset

).
 In current state-of-the art autonomous navigation applications (
\series bold
DS: add citations) 
\series default
cameras give observations with frequency of 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
xxx
\end_layout

\end_inset

 and the total latency, from acquiring the images to processing them, is
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
xxx
\end_layout

\end_inset

 ms.
 To obtain more agile systems, we need to use faster sensors and low-latency
 processing.
\end_layout

\begin_layout Standard
In this paper, we consider the lowest-latency sensor available, called Dynamic
 Vision Sensor (DVS) and how it can be incorporated in a robotic system
 for the application of pose tracking.
 The main difference of a DVS with respect to a normal CMOS camera is that
 the data is transmitted as a series of 
\emph on
events
\emph default
 (
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:DVS-camera"

\end_inset

).
 Intuitively, the events generated can be interpreted as the sign of the
 derivative of the luminance, but this is just an idealization (
\begin_inset CommandInset ref
LatexCommand formatted
reference "sec:The-DVS-camera"

\end_inset

 describes the principles behind the device).
 These events are fired not unlike spikes in a biological visual system,
 as they respond to 
\emph on
change
\emph default
 in the perceived luminance in fact, 
\begin_inset Quotes eld
\end_inset

silicon retina
\begin_inset Quotes erd
\end_inset

 is a nickname for the DVS.
 But the DVS circuits are much faster than a slow neuron: events are generated
 with a latency of 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
xxx
\end_layout

\end_inset

 Âµs.
 Therefore, potentially we could obtain sensing pipelines with a negligible
 latency compared to dynamics of the platform.
 Moreover, compared to normal high speed cameras, the data output and thus
 the processing is reduced, as only change is advertised by the camera.
\end_layout

\begin_layout Standard
We are a few years to the goal, however.
 The DVS camera, though currently available commercially, has a few limitations,
 such as the limited resolution (
\begin_inset Formula $128\times128$
\end_inset

 pixels), and it is too heavy to be attached on current agile drones.
 These problems will be solved shortly; here we turn our attention on how
 we could use the data from a DVS for autonomous navigation of flying drones.
\end_layout

\begin_layout Standard
The application that we show here is localization based on tracking of Active
 LED Markers (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
ALMs
\end_layout

\end_inset

).
 These are blinking LEDs at high frequency (
\begin_inset Formula $>1\,\mbox{kHz}$
\end_inset

).
 The DVS is fast enough to be able to estimate the blinking frequency.
 Therefore, we can detect not only the position, but, assuming that each
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
ALM
\end_layout

\end_inset

 is given a slightly different blinking frequency, also the identity of
 the markers, thus simplifying data association.
 We envision that this system could be used for inter-robot localization
 for high-speed acrobatic maneuvers, or that, in applications such as rescue
 robotics these markers could be left in the environment to facilitate cooperati
ve mapping.
\end_layout

\begin_layout Standard
It is clear that the way we do computer vision must be completely rethought.
 It is possible to integrate the events of a DVS camera to simulate a regular
 CMOS frame, on which to do standard image processing, however, that is
 not what you would want to do, because accumulating.
 Ideally, to have the lowest latency for the sensing pipeline, one would
 want each single event to be be reflected in a small but instantaneous
 change in the commands given to the actuators.
 Therefore, we really want to consider approaches that possibly use the
 information contained in each single event.
\end_layout

\begin_layout Standard
We have found two main approaches to handling event data.
 So far the DVS events are processed using features (such as lines) that
 are tracked through time (
\series bold
CB: add citations/expand)
\series default
.
 This approach works well when the camera is static, because the output
 is very sparse, and the input contains the features that are able to be
 tracked.
 In this paper we use a somewhat different approach.
 We found out that mounting a DVS camera on a flying robot creates a new
 set of challenges.
 Because of the apparent motion of the environment, the input is not sparse
 anymore.
 Moreover, while in controlled conditions the DVS camera parameters can
 be tuned to obtain the best performance, a robot must be able to work in
 a wider range of environmental conditions and be robust to interferences.
 To achieve 
\end_layout

\begin_layout Standard
The approach presented in this paper is tunable such that  a bit of latency
 can be sacrificed to obtain a more robust 
\end_layout

\begin_layout Standard
In the end, we sacrified some latency to be robust to noise.
 In obtain latencies of 
\end_layout

\begin_layout Standard
In the end 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
As this utilization of asynchronous vision is a rather novel approach in
 robotics it would be interesting to use this camera in other navigational
 tasks in future projects, for example for visual SLAM on autonomous ground
 vehicles.
 While small image features as used in SIFT 
\begin_inset CommandInset citation
LatexCommand cite
key "SIFT"

\end_inset

 might be difficult to use due to resolution line feature extraction, as
 describe in 
\begin_inset CommandInset citation
LatexCommand cite
key "LineTracking"

\end_inset

, could be a feasible approach.
 Additionally, as edges are the natural source for DVS events it would have
 an advantage in terms of processing compared to normal cameras.
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Software and datasets are available at the website 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
xxx
\end_layout

\end_inset


\end_layout

\begin_layout Section
The DVS camera
\begin_inset CommandInset label
LatexCommand label
name "sec:The-DVS-camera"

\end_inset


\end_layout

\begin_layout Standard

\series bold
CB/TB: could you write a short description (~1.5 columns) of the DVS camera
 that could be understandable to a computer scientist? Also feel free to
 write more, I will edit it down to space constraints.
 I wrote down a few points that I'd like to make regarding future improvements
 that are relevant to robotics.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

{
\backslash
color[rgb]{0.7,0.7,0.7}
\backslash
rule{2.6cm}{3cm}}
\end_layout

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
DVS camera 
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

{
\backslash
color[rgb]{0.7,0.7,0.7}
\backslash
rule{2.6cm}{3cm}}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Response to circular stimulus
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

{
\backslash
color[rgb]{0.7,0.7,0.7}
\backslash
rule{2.6cm}{3cm}}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Drone rotor
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:DVS-camera"

\end_inset

DVS camera and its output
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "boerlin09getting"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "lichtsteiner08asynchronous"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "etienne-cummings99intelligent"

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "oster08quantification"

\end_inset


\end_layout

\begin_layout Itemize
Future improvements:
\end_layout

\begin_deeper
\begin_layout Itemize
miniaturization
\end_layout

\begin_layout Itemize
higher resolution
\end_layout

\begin_layout Itemize
buffer able to handle more events
\end_layout

\begin_layout Itemize
inclusion of a normal CMOS camera
\end_layout

\begin_layout Itemize
easier to tune
\end_layout

\end_deeper
\begin_layout Section
Hardware setup and event data
\begin_inset CommandInset label
LatexCommand label
name "sec:Hardware-setup-and"

\end_inset


\end_layout

\begin_layout Itemize
This section describes the basic hardware setup and how the data looks like.
\end_layout

\begin_layout Subsection
Active LED Markers (ALMs)
\end_layout

\begin_layout Itemize
We have a set of blinking LEDs
\end_layout

\begin_layout Itemize
Each LEDs blinks at a different frequency.
\end_layout

\begin_layout Subsection
Events
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:events-hist"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Events data in practice
\end_layout

\begin_layout Itemize
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:events-hist"

\end_inset

 shows how the data looks like.
 
\end_layout

\begin_deeper
\begin_layout Itemize
In this case, the LEDs are fixed in the environment and a 
\emph on
fixed 
\emph default
camera is looking at them.
\end_layout

\begin_layout Itemize
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:events-hist"

\end_inset


\emph on
a
\emph default
 shows the histogram of events from one pixel
\end_layout

\begin_layout Itemize
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:events-hist"

\end_inset


\emph on
b
\emph default
 shows the sequence of events from one particular pixel.
 
\end_layout

\end_deeper
\begin_layout Itemize
Note also the halo in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:events-hist"

\end_inset


\emph on
a
\emph default
 cannot be explained by the refractive properties of the optics of the camera
 and is probably due to properties.
\end_layout

\begin_layout Itemize
The idea
\end_layout

\begin_layout Itemize
Experimentally the interval is actually very repeatable
\end_layout

\begin_layout Subsection
Alternate events and motion
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:filtering-switch"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
We go from events to 
\begin_inset Quotes eld
\end_inset

alternate events
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
This needs a buffer
\end_layout

\begin_layout Itemize
This series now has the polarity
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:switch-hist"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:switch-hist"

\end_inset


\emph on
a
\emph default
 shows the histogram
\end_layout

\begin_layout Itemize
The frequency peaks are clearly visible in this histogram
\end_layout

\begin_layout Itemize
What about motion?
\end_layout

\begin_deeper
\begin_layout Itemize
We see that, following motion, in 
\begin_inset CommandInset ref
LatexCommand formatted
reference "fig:switch-hist"

\end_inset


\emph on
b 
\emph default
the peaks are clearly visible.
\end_layout

\begin_layout Itemize
There is also a 
\end_layout

\begin_layout Itemize
Of course all of this depends on the statistics of the image.
\end_layout

\end_deeper
\begin_layout Section
Tracking algorithm
\end_layout

\begin_layout Subsection
From raw events to sequence events
\end_layout

\begin_layout Subsection
Particle filters
\end_layout

\begin_layout Subsection
Estimation
\end_layout

\begin_layout Subsection
3D Reconstruction
\end_layout

\begin_layout Subsubsection

\end_layout

\end_body
\end_document
